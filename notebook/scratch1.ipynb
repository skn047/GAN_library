{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# data augmention(preprocess)\n",
    "class data_aug:\n",
    "    def resize(self, input_image, real_image, height, width):\n",
    "        input_image = tf.image.resize(input_image, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        real_image = tf.image.resize(real_image, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "        return input_image, real_image\n",
    "\n",
    "    def random_crop(self, input_image, real_image):\n",
    "        stack_image = tf.stack([input_image, real_image], axis=0)\n",
    "        cropped_image = tf.image.random_crop(stack_image, size=[2, 256, 256, 3])\n",
    "\n",
    "        return cropped_image[0], cropped_image[1]\n",
    "\n",
    "    @tf.function()\n",
    "    def random_jitter(self, input_image, real_image):\n",
    "        input_image, real_image = self.resize(input_image, real_image, 286, 286)\n",
    "        input_image, real_image = self.random_crop(input_image, real_image)\n",
    "\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            input_image = tf.image.flip_left_right(input_image)\n",
    "            real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "        return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_image(image_file):\n",
    "    image = load(image_file)\n",
    "\n",
    "    return image\n",
    "\n",
    "train_input_dataset_path = os.listdir('data/train/')\n",
    "train_input_dataset_path = [os.path.join(os.path.abspath('data/train/'), p) for p in train_input_dataset_path]\n",
    "\n",
    "test_input_dataset_path = os.listdir('data/test/')\n",
    "test_input_dataset_path = [os.path.join(os.path.abspath('data/test/'), p) for p in test_input_dataset_path]\n",
    "\n",
    "train_aug_dataset_path = os.listdir('data/aug/train')\n",
    "train_aug_dataset_path = [os.path.join(os.path.abspath('data/aug/train'), p) for p in train_aug_dataset_path]\n",
    "\n",
    "test_aug_dataset_path = os.listdir('data/aug/test')\n",
    "test_aug_dataset_path = [os.path.join(os.path.abspath('data/aug/test'), p) for p in test_aug_dataset_path]\n",
    "\n",
    "train_input_dataset = tf.data.Dataset.from_tensor_slices(train_input_dataset_path)\n",
    "train_input_dataset = train_input_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_input_dataset = tf.data.Dataset.from_tensor_slices(test_input_dataset_path)\n",
    "test_input_dataset = test_input_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_aug_dataset = tf.data.Dataset.from_tensor_slices(train_aug_dataset_path)\n",
    "train_aug_dataset = train_aug_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_aug_dataset = tf.data.Dataset.from_tensor_slices(test_aug_dataset_path)\n",
    "test_aug_dataset = test_aug_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_input_dataset, train_aug_dataset))\n",
    "test_dataset = tf.data.Dataset.zip((test_input_dataset, test_aug_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# network module\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.down_stack = [\n",
    "            downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "            downsample(128, 4), # (bs, 64, 64, 128)\n",
    "            downsample(256, 4), # (bs, 32, 32, 256)\n",
    "            downsample(512, 4), # (bs, 16, 16, 512)\n",
    "            downsample(512, 4), # (bs, 8, 8, 512)\n",
    "            downsample(512, 4), # (bs, 4, 4, 512)\n",
    "            downsample(512, 4), # (bs, 2, 2, 512)\n",
    "            downsample(512, 4), # (bs, 1, 1, 512)\n",
    "        ]\n",
    "\n",
    "        self.up_stack = [\n",
    "            upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "            upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "            upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "            upsample(512, 4), # (bs, 16, 16, 1024\n",
    "            upsample(256, 4), # (bs, 32, 32, 512)\n",
    "            upsample(128, 4), # (bs, 64, 64, 256)\n",
    "            upsample(64, 4), # (bs, 128, 128, 128)\n",
    "        ]\n",
    "\n",
    "        self.last = tf.keras.layers.Conv2DTranspose(3, 4, strides=2,padding='same', kernel_initializer=tf.random_normal_initializer(0, 0.02), activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        x = inputs\n",
    "\n",
    "        skips = []\n",
    "        for down in self.down_stack:\n",
    "            x = down(x)\n",
    "            skips.append(x)\n",
    "        skips = reversed(skips[:-1])\n",
    "\n",
    "        for up, skip in zip(self.up_stack, skips):\n",
    "            x = up(x)\n",
    "            x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "        output = self.last(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "LAMDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target-gen_output))\n",
    "    total_gen_loss = gan_loss + (LAMDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.down_stack = [downsample(64, 4, False), downsample(128, 4), downsample(256, 4)]\n",
    "        self.zero_pad1 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.zero_pad2 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=tf.random_normal_initializer(0, 0.02), use_bias=False)\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs = input + target(concatenated)\n",
    "        inp, tar = inputs\n",
    "        x = tf.concat([inp, tar], 0)\n",
    "        # x = tf.reshape(x, [-1, 286, 286, 6])\n",
    "        for down in self.down_stack:\n",
    "            x = down(x)\n",
    "        x = self.conv(self.zero_pad1(x))\n",
    "        x = self.zero_pad2(self.leaky_relu(self.batchnorm(x)))\n",
    "        output = self.last(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "inputs = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "    log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# training\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        print(\"OK\")\n",
    "        # disc_input1 = tf.keras.layers.Concatenate()[input_image, target]\n",
    "        # disc_input1 = tf.keras.layers.Concatenate()[input_image, gen_output]\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "        print(disc_real_output.shape)\n",
    "        print(disc_generated_output.shape)\n",
    "        print(\"OK\")\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, generator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "    stack_image = tf.stack([input_image, real_image], axis=0)\n",
    "    print(stack_image)\n",
    "    cropped_image = tf.image.random_crop(stack_image, size=[2, -1, 256, 256, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "\n",
    "@tf.function\n",
    "def random_jitter(input_image, real_image):\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "    return input_image, real_image\n",
    "\n",
    "@tf.function\n",
    "def aug_image(input_image, real_image):\n",
    "    input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        # for example_input, example_target in test_ds.take(1)\n",
    "\n",
    "        for n, (input_image, target) in enumerate(train_ds.batch(8).shuffle(8)):\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            input_image, target = aug_image(input_image, target)\n",
    "            train_step(input_image, target, epoch)\n",
    "        print()\n",
    "\n",
    "        # saving (checkpoint) the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                        time.time()-start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n      <iframe id=\"tensorboard-frame-5424aff8d5a378bf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-5424aff8d5a378bf\");\n          const url = new URL(\"/\", window.location);\n          url.port = 6006;\n          frame.src = url;\n        })();\n      </script>\n  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "(8, 30, 30, 1)\n",
      "(8, 30, 30, 1)\n",
      "OK\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-206-5c1d50a496b4>:28 train_step  *\n        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:444 apply_gradients\n        kwargs={\"name\": name})\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1949 merge_call\n        return self._merge_call(merge_fn, args, kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1956 _merge_call\n        return merge_fn(self._strategy, *args, **kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:488 _distributed_apply\n        var, apply_grad_to_update_var, args=(grad,), group=False))\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1543 update\n        return self._update(var, fn, args, kwargs, group)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:2174 _update\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:2180 _update_non_slot\n        result = fn(*args, **kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:470 apply_grad_to_update_var\n        update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py:207 _resource_apply_dense\n        use_locking=self._use_locking)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/training/gen_training_ops.py:1436 resource_apply_adam\n        use_nesterov=use_nesterov, name=name)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 3 in both shapes must be equal, but are 1 and 512. Shapes are [4,4,512,1] and [4,4,512,512]. for 'Adam_1/Adam/update_10/ResourceApplyAdam' (op: 'ResourceApplyAdam') with input shapes: [], [], [], [], [], [], [], [], [], [4,4,512,512].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-91e4b5f743cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-182-9369eb5849e4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_ds, epochs, test_ds)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maug_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-206-5c1d50a496b4>:28 train_step  *\n        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:444 apply_gradients\n        kwargs={\"name\": name})\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1949 merge_call\n        return self._merge_call(merge_fn, args, kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1956 _merge_call\n        return merge_fn(self._strategy, *args, **kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:488 _distributed_apply\n        var, apply_grad_to_update_var, args=(grad,), group=False))\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:1543 update\n        return self._update(var, fn, args, kwargs, group)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:2174 _update\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py:2180 _update_non_slot\n        result = fn(*args, **kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:470 apply_grad_to_update_var\n        update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py:207 _resource_apply_dense\n        use_locking=self._use_locking)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/training/gen_training_ops.py:1436 resource_apply_adam\n        use_nesterov=use_nesterov, name=name)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/naoki/anaconda3/envs/tensorflow-new/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 3 in both shapes must be equal, but are 1 and 512. Shapes are [4,4,512,1] and [4,4,512,512]. for 'Adam_1/Adam/update_10/ResourceApplyAdam' (op: 'ResourceApplyAdam') with input shapes: [], [], [], [], [], [], [], [], [], [4,4,512,512].\n"
     ]
    }
   ],
   "source": [
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# for input, real in train_dataset.batch(1):\n",
    "#     input_image = input.numpy().reshape((286, 286, 3))\n",
    "#     cv2.imwrite(\"/home/naoki/input.png\", input_image)\n",
    "#     input_image = plt.imread(\"/home/naoki/input.png\")\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(input_image)\n",
    "\n",
    "#     real_image = real.numpy().reshape((286, 286, 3))\n",
    "#     cv2.imwrite(\"/home/naoki/real.png\", real_image)\n",
    "#     real_image = plt.imread(\"/home/naoki/real.png\")\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(real_image)\n",
    "#     first_input_batch = next(iter(train_dataset))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/naoki/anaconda3/envs/tensorflow-new/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Tensorflow-new",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "tensorflow-new"
  },
  "name": "Untitled1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
